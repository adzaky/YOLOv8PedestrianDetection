{"cells":[{"cell_type":"markdown","metadata":{"id":"0fRV0VyTFa4v"},"source":["## Before you start\n","\n","Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nD3EEfKzFftV"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO4MWPmnFk7m"},"outputs":[],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"hZkBCNk9F6NO"},"source":["## Download video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkKyyyNxu5EC"},"outputs":[],"source":["!pip install -q gdown\n","%cd {HOME}\n","!gdown '18UPK68fD6sjAbtGH9mHU8DqFkNO1BEe_'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3DjvPRiGIht"},"outputs":[],"source":["SOURCE_VIDEO_PATH = f\"{HOME}/video_jalan_kaki.mp4\""]},{"cell_type":"markdown","metadata":{"id":"C5w5bHwTGUdp"},"source":["## Install YOLOv8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S2kB2mCmGPmL"},"outputs":[],"source":["!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"markdown","metadata":{"id":"c-Fg7kPTG1xL"},"source":["## Install Roboflow Supervision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dbt0QFEn9OFu"},"outputs":[],"source":["!pip install supervision\n","\n","from IPython import display\n","display.clear_output()\n","\n","import supervision as sv\n","print(\"supervision.__version__:\", sv.__version__)"]},{"cell_type":"markdown","metadata":{"id":"Y99ZDFi4G9zU"},"source":["## Load pre-trained YOLOv8 model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxe67PQVHBCA"},"outputs":[],"source":["MODEL = \"yolov8x.pt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-7SBD_bHDuQ"},"outputs":[],"source":["from ultralytics import YOLO\n","\n","model = YOLO(MODEL)\n","model.fuse()"]},{"cell_type":"markdown","metadata":{"id":"COTWRxDhHIz3"},"source":["## Predict and annotate single frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEx7Wn7F9Tlc"},"outputs":[],"source":["# dict maping class_id to class_name\n","CLASS_NAMES_DICT = model.model.names\n","\n","# class_ids of interest - person\n","selected_classes = [0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"noOycxILHjYI"},"outputs":[],"source":["import supervision as sv\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuNPZ2hvHeZV"},"outputs":[],"source":["# create frame generator\n","generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n","# create instance of BoxAnnotator\n","box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n","# acquire first video frame\n","iterator = iter(generator)\n","frame = next(iterator)\n","# model prediction on single frame and conversion to supervision Detections\n","results = model(frame, verbose=False)[0]\n","\n","# convert to Detections\n","detections = sv.Detections.from_ultralytics(results)\n","# only consider class id from selected_classes define above\n","detections = detections[np.isin(detections.class_id, selected_classes)]\n","\n","# format custom labels\n","labels = [\n","    f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n","    for _, _, confidence, class_id, _ in detections\n","]\n","\n","# annotate and display frame\n","anotated_frame=box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n","\n","%matplotlib inline\n","sv.plot_image(anotated_frame, (16,16))"]},{"cell_type":"markdown","metadata":{"id":"Kc0NETYnJWex"},"source":["## Predict and annotate whole video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Qwykp5K9VdK"},"outputs":[],"source":["# settings\n","LINE_START = sv.Point(50, 360)\n","LINE_END = sv.Point(1280-50, 360)\n","\n","TARGET_VIDEO_PATH = f\"{HOME}/Result_video.mp4\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTBvc5FDJcyw"},"outputs":[],"source":["sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdnkBZVn9Xyb"},"outputs":[],"source":["# create BYTETracker instance\n","byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n","\n","# create VideoInfo instance\n","video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n","\n","# create frame generator\n","generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n","\n","# create LineZone instance, it is previously called LineCounter class\n","line_zone = sv.LineZone(start=LINE_START, end=LINE_END)\n","\n","# create instance of BoxAnnotator\n","box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n","\n","# create instance of TraceAnnotator\n","trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n","\n","# create LineZoneAnnotator instance, it is previously called LineCounterAnnotator class\n","line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n","\n","# define call back function to be used in video processing\n","def callback(frame: np.ndarray, index:int) -> np.ndarray:\n","    # model prediction on single frame and conversion to supervision Detections\n","    results = model(frame, verbose=False)[0]\n","    detections = sv.Detections.from_ultralytics(results)\n","    # only consider class id from selected_classes define above\n","    detections = detections[np.isin(detections.class_id, selected_classes)]\n","    # tracking detections\n","    detections = byte_tracker.update_with_detections(detections)\n","    labels = [\n","        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"   #labeling\n","        for _, _, confidence, class_id, tracker_id\n","        in detections\n","    ]\n","    annotated_frame = trace_annotator.annotate(\n","        scene=frame.copy(),\n","        detections=detections\n","    )\n","    annotated_frame=box_annotator.annotate(\n","        scene=annotated_frame,\n","        detections=detections,\n","        labels=labels)\n","\n","    # update line counter\n","    line_zone.trigger(detections)\n","    # return frame with box and line annotated result\n","    return  line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n","\n","# process the whole video\n","sv.process_video(\n","    source_path = SOURCE_VIDEO_PATH,\n","    target_path = TARGET_VIDEO_PATH,\n","    callback=callback\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1BP1MBFrLkzYCMXxI_tGOdvz75m8gXded","timestamp":1703246671541},{"file_id":"1IXdKyuDH23HLZANH8q9OSB5YVEc4TV4E","timestamp":1703263266649}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}